如果只是随便让 Claude Code 写点代码，你只能看到**局部提示词**，而不是完整的系统设计。

要真正理解它的工作机制，需要设计一个**能触发完整工作流的测试场景**，让它：

* 读取代码
* 修改代码
* 创建文件
* 调用工具
* 多轮交互
* 出错后修复
* 运行测试

这样才能看到：

> Claude Code 的完整系统提示词结构 + 工具调用策略 + 决策逻辑

---

# 一、测试场景设计原则

一个好的分析场景要满足 5 个条件：

| 条件     | 为什么重要     |
| ------ | --------- |
| 多文件项目  | 触发代码检索提示词 |
| 有 bug  | 触发诊断与修改逻辑 |
| 有测试    | 触发测试相关工具  |
| 有新功能需求 | 触发规划与生成逻辑 |
| 需要多轮交互 | 触发对话管理策略  |

---

# 二、推荐测试场景（最全面的一种）

## 场景：修复并扩展一个小型 Web API 项目

### 项目结构（你可以本地新建）

```
demo_project/
│
├── app.py
├── utils.py
├── test_app.py
└── requirements.txt
```

---

### app.py

```python
from flask import Flask, request, jsonify
from utils import add

app = Flask(__name__)

@app.route("/add", methods=["POST"])
def add_api():
    data = request.get_json()
    a = data.get("a")
    b = data.get("b")
    result = add(a, b)
    return jsonify({"result": result})

if __name__ == "__main__":
    app.run(debug=True)
```

---

### utils.py（故意埋 bug）

```python
def add(a, b):
    return a - b   # bug：这里应该是加法
```

---

### test_app.py

```python
from utils import add

def test_add():
    assert add(2, 3) == 5
```

---

### requirements.txt

```
flask
pytest
```

---

# 三、完整测试流程（一步步触发所有能力）

按顺序给 Claude Code 下这些指令。

---

## 步骤1：项目理解（触发代码读取）

在项目根目录运行：

```
claude code
```

输入：

```
请分析这个项目的结构，并解释每个文件的作用。
```

### 你会看到：

* 文件读取工具调用
* 项目结构总结
* 系统提示词中的“代码分析规则”

---

## 步骤2：发现 bug（触发测试推理）

输入：

```
这个项目的测试会失败吗？如果会，原因是什么？
```

### 会触发：

* 读取 test 文件
* 分析函数逻辑
* 推理 bug

---

## 步骤3：要求修复 bug（触发代码修改工具）

输入：

```
请修复这个 bug，并保证测试通过。
```

### 会触发：

* 编辑文件工具
* 差异补丁生成
* 修改策略提示词

这是非常关键的一步。

---

## 步骤4：新增功能（触发规划能力）

输入：

```
请为这个项目新增一个 /multiply 接口，并补充对应测试。
```

### 会触发：

* 新文件或新函数创建
* 多文件修改
* 测试生成
* 工具调用链

---

## 步骤5：复杂任务（触发多步规划）

输入：

```
请把这个项目重构成一个更规范的结构：
- 使用蓝图（Blueprint）
- 增加错误处理
- 增加日志
```

### 会触发：

* 长上下文 prompt
* 多步规划
* 多次工具调用
* 大规模文件修改

这一步最能看出：

> Claude Code 的“工程级系统提示词”是怎么约束行为的

---

# 四、抓包时重点观察的内容

你在 mitmweb 里不要只看 prompt 内容，要按下面结构分析：

---

## 1. 系统提示词结构

重点看：

```
system:
  - 工具规则
  - 行为限制
  - 输出格式要求
```

关注：

* 是否分模块
* 是否有角色定义
* 是否有安全策略

---

## 2. 工具调用策略

看每次请求中：

```
tools: [...]
tool_choice: ...
```

分析：

* 什么情况下调用 read
* 什么情况下调用 edit
* 是否有强制流程

---

## 3. 上下文管理方式

重点看：

* 每次请求附带哪些文件内容
* 是否有摘要机制
* 是否只传局部代码

---

## 4. 修改策略

在 edit 操作时观察：

* 是整文件替换
* 还是 diff patch
* 是否有“先解释再改”的约束

---

# 五、进阶测试场景（如果你想更深入）

如果你想看到更复杂的提示词行为，可以再加一个场景：

---

## 场景2：引入依赖冲突

在 requirements.txt 中加入：

```
flask==1.0
werkzeug==3.0
```

然后让 Claude：

```
这个项目启动时报错，请帮我修复依赖问题。
```

这会触发：

* 环境推理
* 依赖修改
* 更复杂的系统提示词路径

---

# 六、一句话总结这个测试设计

这个场景可以触发 Claude Code 的：

* 代码理解
* bug 分析
* 自动修改
* 新功能生成
* 多步规划
* 工具调用
* 上下文管理

基本能还原出：

> Claude Code 的完整工作流和系统 prompt 架构
